# Chat with Vision LLM


## Overview

**Chat with Vision LLM** is a GPT-4V-level multi-modal language model (MLLM) designed to handle single image, multi-image, and video inputs on your mobile device. Powered by [**MiniCPM-V 2.6**](https://huggingface.co/openbmb/MiniCPM-V-2_6), this is the most advanced model in the MiniCPM-V series, delivering cutting-edge performance and versatility for your applications.

## Getting Started

Follow these steps to set up and run the project:

### 1. Install Dependencies

Ensure all necessary packages are installed by running:

```bash
pip install -r requirements.txt
```

### 2. Start the API Server

Launch the API server powered by [LitServe](https://github.com/Lightning-AI/LitServe):

```bash
python server.py
```

### 3. Launch the Streamlit App

Start the Streamlit application with the following command:

```bash
streamlit run app.py
```

## About

This project is developed and maintained with ❤️ by [Bhimraj Yadav](https://github.com/bhimrazy).
